{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import struct\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4]\n",
    "norm = 0\n",
    "for i in x:\n",
    "    norm += np.exp(i)\n",
    "print(np.exp(x)/norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入数据\n",
    "def load_mnist():\n",
    "    labels_path = os.path.join('./data/train/train-labels.idx1-ubyte')\n",
    "    images_path = os.path.join('./data/train/train-images.idx3-ubyte')\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data, label = load_mnist()\n",
    "img = data[0].reshape(28,28)\n",
    "plt.imshow(img, cmap='Greys', interpolation='nearest')\n",
    "plt.title(label[0])\n",
    "plt.show()\n",
    "print(data.shape)\n",
    "# print(X_train[0])\n",
    "print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:50000,:]\n",
    "train_label = label[:50000]\n",
    "val_data = data[50000:,:]\n",
    "val_label = label[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_label = np.zeros([len(label),10])\n",
    "for i in range(len(label)):\n",
    "    mul_label[i,label[i]] = 1\n",
    "mul_train_label = mul_label[:50000]\n",
    "mul_val_label = mul_label[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x, deriv=False):\n",
    "    if deriv == True:\n",
    "        x[np.where(x > 0)]=1\n",
    "        x[np.where(x<=0)]=0\n",
    "        return x\n",
    "    else:\n",
    "        mask = x > 0\n",
    "        return x*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    norm = 0\n",
    "    for i in z:\n",
    "        norm += np.exp(i)\n",
    "    return np.exp(z)/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchNorm1d(z):\n",
    "    s = np.std(z)\n",
    "    E = z.mean()\n",
    "    z = (z - E) / ((s + 1e-5) **0.5) \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_NN(object):\n",
    "    def __init__(self):\n",
    "        self.x = np.zeros(784)                         # input输入\n",
    "        self.w = 0.01 * np.random.randn(100,784)       # I-H权值\n",
    "        self.netj = np.zeros(100)                      # hidden输入\n",
    "        self.y = np.zeros(100)                         # hidden输出\n",
    "        self.v = 0.01 * np.random.randn(10,100)        # H-O权值\n",
    "        self.netk = np.zeros(10)                       # output输入\n",
    "        self.z = np.zeros(10)                          # output输出\n",
    "        self.gradw = np.zeros([100,784])\n",
    "        self.gradv = np.zeros([10,120])\n",
    "        self.ita = 1e-3\n",
    "        self.momentum = 0.9\n",
    "        \n",
    "    \n",
    "    def Forward(self, x):\n",
    "        self.x = (x/255)*0.99 + 0.01\n",
    "        self.netj = np.dot(self.w, self.x)\n",
    "        self.netj = BatchNorm1d(self.netj)\n",
    "        self.y = ReLU(self.netj)\n",
    "        \n",
    "        self.netk = np.dot(self.v, self.y)\n",
    "        self.netk = BatchNorm1d(self.netk)\n",
    "        self.z = softmax(ReLU(self.netk))\n",
    "        \n",
    "        \n",
    "    def Backpropagation(self, t):\n",
    "        delta1 = np.zeros(self.z.shape)        \n",
    "        delta1 = ((t - self.z) * ReLU(self.netk, True)).T\n",
    "        self.gradv = self.momentum * self.gradv + self.ita * np.outer(delta1, self.y)\n",
    "        self.v += self.gradv\n",
    "        \n",
    "        delta2 = np.zeros(len(self.y))\n",
    "        for i in range(len(delta2)):\n",
    "            delta2[i] = np.dot(delta1, self.v[:, i])\n",
    "        delta2 = ReLU(delta2 * self.netj, True)\n",
    "        self.gradw = self.momentum * self.gradw + self.ita * np.outer(delta2, self.x)\n",
    "        self.w += self.gradw\n",
    "\n",
    "    def loss(self, label):\n",
    "        return 0.5 * np.linalg.norm(label - self.z)\n",
    "    \n",
    "    def Set(self, w, v):\n",
    "        self.w = w\n",
    "        self.v = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoches, net, train_data, mul_train_label, val_data, val_label):\n",
    "    history = []\n",
    "    train_losses = []\n",
    "    val_acc = []\n",
    "        \n",
    "    for epoch in range(epoches):\n",
    "        loss = 0\n",
    "        for i in range(len(train_data)):\n",
    "            # 采用单样本训练法\n",
    "            net.Forward(train_data[i])            \n",
    "            net.Backpropagation(mul_train_label[i])\n",
    "\n",
    "            loss += net.loss(mul_train_label[i])\n",
    "            # if i%10000 == 0:\n",
    "            #     print(\"loss in %d is:%f\" %(i,loss))\n",
    "        # 每轮训练进行一次验证集验证，并将结果记录，便于结束后绘制图像\n",
    "        acc = evaluate(net, val_data, val_label)\n",
    "        train_losses.append(loss)\n",
    "        val_acc.append(acc)\n",
    "        # 打印验证结果\n",
    "        print(\"epoch:%d  train_loss=%f  val_acc=%f\" %(epoch, loss, acc))\n",
    "        net.ita *= 0.99 ** (epoch//2) \n",
    "\n",
    "    return train_losses, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, val_data, val_label):\n",
    "    if len(val_data) == 784:\n",
    "        net.Forward(val_data)\n",
    "        if(np.argmax(net.z) == np.argmax(val_label)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        acc = 0\n",
    "        for i in range(len(val_label)):\n",
    "            net.Forward(val_data[i])\n",
    "            if np.argmax(net.z) == np.argmax(val_label[i]):\n",
    "                acc += 1\n",
    "        return acc/len(val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net = my_NN()\n",
    "print(net.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5重交叉验证\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoches = 30\n",
    "train_losses_stack = []\n",
    "val_acc_stack = []\n",
    "net_stack = []\n",
    "ford = 1\n",
    "for X_train_i, X_test_i in kf.split(data):\n",
    "    net = my_NN()\n",
    "    train_losses, val_acc = fit(epoches, net, data[X_train_i], mul_label[X_train_i], \\\n",
    "                                data[X_test_i], mul_label[X_test_i])\n",
    "    train_losses_stack.append(train_losses)\n",
    "    val_acc_stack.append(val_acc)\n",
    "    net_stack.append(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(net,train_data[100],mul_train_label[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=5,\n",
    "    sharex=True,\n",
    "    sharey=True, )\n",
    "\n",
    "ax = ax.flatten()\n",
    "for i in range(5):\n",
    "    ax[i].plot(range(0,epoches), train_losses_stack[i])\n",
    "    ax[i].xlabel(\"epoch_num\")\n",
    "    ax[i].ylabel(\"loss\")\n",
    "for i in range(5):\n",
    "    ax[i+5].plot(range(0,epoches), val_acc_stack[i])\n",
    "    ax[i+5].xlabel(\"epoch_num\")\n",
    "    ax[i+5].ylabel(\"val_acc\")\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val_acc_stack)):\n",
    "    print(val_acc_stack[i][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(evaluate(net_stack[i],val_data,mul_val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stack_w = []\n",
    "stack_v = []\n",
    "for i in range(5):\n",
    "    stack_w.append(net_stack[i].w)\n",
    "    stack_v.append(net_stack[i].v)\n",
    "net = my_NN()\n",
    "net.Set(np.array(stack_w).mean(0), np.array(stack_v).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, data):\n",
    "    predict = np.zeros(len(data))\n",
    "    for i in range(len(data)):\n",
    "        net.Forward(data[i])\n",
    "        predict[i] = np.argmax(net.z)\n",
    "        print(\"No. %d is %f\" %(i,predict[i]))\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "# 测试集预测\n",
    "\n",
    "test_data = genfromtxt('data/test_data.csv',delimiter=',')\n",
    "test_data = test_data[1:,:784]\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = predict(net, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写入excel\n",
    "# 记录测试结果\n",
    "import csv\n",
    "with open(\"task_test_label.csv\",\"w\", newline=\"\") as csvfile: \n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"index\",\"label\"])\n",
    "    for i in range(len(predict)):\n",
    "        writer.writerow([i,int(predict[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = test_data.reshape(10000,28,28)\n",
    "num = 4\n",
    "plt.imshow(img[num], cmap='Greys', interpolation='nearest')\n",
    "plt.title(predict[num])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 100\n",
    "plt.imshow(img[num], cmap='Greys', interpolation='nearest')\n",
    "plt.title(predict[num])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore(1.5.0)",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
